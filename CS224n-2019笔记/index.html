



<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Looper's personal notes">
      
      
        <link rel="canonical" href="https://looperxx.github.io/CS224n-2019笔记/">
      
      
        <meta name="author" content="Looper - Xiao Xu">
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="ja">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.2.0">
    
    
      
        <title>CS224n-2019笔记 - Looper's wiki</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.750b69bd.css">
      
      
    
    
      <script src="../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "UA-XXXXXXXX-X", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    <body dir="ltr">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#cs224n-2019" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://looperxx.github.io" title="Looper's wiki" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Looper's wiki
            </span>
            <span class="md-header-nav__topic">
              CS224n-2019笔记
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/looperxx/looperxx.github.io/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    looperxx/looperxx.github.io
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href=".." title="Home" class="md-tabs__link">
        Home
      </a>
    
  </li>

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../Linux/" title="Math & CS & Coding" class="md-tabs__link">
          Math & CS & Coding
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../Attention/" title="ML & DL" class="md-tabs__link">
          ML & DL
        </a>
      
    </li>
  

      
        
  
  
    
    
  
  
    <li class="md-tabs__item">
      
        <a href="../自然语言处理简介/" title="NLP" class="md-tabs__link">
          NLP
        </a>
      
    </li>
  

  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../面经/" title="Interview experience" class="md-tabs__link">
          Interview experience
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../MkDocs_demo/" title="For MkDocs" class="md-tabs__link">
          For MkDocs
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://looperxx.github.io" title="Looper's wiki" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Looper's wiki
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/looperxx/looperxx.github.io/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    looperxx/looperxx.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      Math & CS & Coding
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Math & CS & Coding
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Linux/" title="Linux" class="md-nav__link">
      Linux
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Coding Knowledge/" title="重点内容" class="md-nav__link">
      重点内容
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../历年机试/" title="历年机试" class="md-nav__link">
      历年机试
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      ML & DL
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        ML & DL
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Attention/" title="Attention" class="md-nav__link">
      Attention
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Normalization/" title="Normalization" class="md-nav__link">
      Normalization
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Concepts/" title="Concepts" class="md-nav__link">
      Concepts
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../花书经验法则/" title="花书经验法则" class="md-nav__link">
      花书经验法则
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../经典网络/" title="经典网络" class="md-nav__link">
      经典网络
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4" checked>
    
    <label class="md-nav__link" for="nav-4">
      NLP
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        NLP
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-1" type="checkbox" id="nav-4-1">
    
    <label class="md-nav__link" for="nav-4-1">
      简介
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-1">
        简介
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../自然语言处理简介/" title="自然语言处理简介" class="md-nav__link">
      自然语言处理简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../NLP的巨人肩膀/" title="NLP的巨人肩膀" class="md-nav__link">
      NLP的巨人肩膀
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-2" type="checkbox" id="nav-4-2">
    
    <label class="md-nav__link" for="nav-4-2">
      书籍笔记
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-2">
        书籍笔记
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../NLP Concepts/" title="NLP Concepts" class="md-nav__link">
      NLP Concepts
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Neural Reading Comprehension and beyond/" title="Machine Reading Comprehension" class="md-nav__link">
      Machine Reading Comprehension
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3" type="checkbox" id="nav-4-3" checked>
    
    <label class="md-nav__link" for="nav-4-3">
      课程笔记
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-3">
        课程笔记
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019简介/" title="CS224n-2019简介" class="md-nav__link">
      CS224n-2019简介
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        CS224n-2019笔记
      </label>
    
    <a href="./" title="CS224n-2019笔记" class="md-nav__link md-nav__link--active">
      CS224n-2019笔记
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lecture-01-introduction-and-word-vectors" title="Lecture 01 Introduction and Word Vectors" class="md-nav__link">
    Lecture 01 Introduction and Word Vectors
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#human-language-and-word-meaning" title="Human language and word meaning" class="md-nav__link">
    Human language and word meaning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word2vec-introduction" title="Word2vec introduction" class="md-nav__link">
    Word2vec introduction
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word2vec-objective-function" title="Word2vec objective function" class="md-nav__link">
    Word2vec objective function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word2vec-prediction-function" title="Word2vec prediction function" class="md-nav__link">
    Word2vec prediction function
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes-01-introduction-svd-and-word2vec" title="Notes 01  Introduction, SVD and Word2Vec" class="md-nav__link">
    Notes 01  Introduction, SVD and Word2Vec
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#introduction-to-natural-language-processing" title="Introduction to Natural Language Processing" class="md-nav__link">
    Introduction to Natural Language Processing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word-vectors" title="Word Vectors" class="md-nav__link">
    Word Vectors
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#svd-based-methods" title="SVD Based Methods" class="md-nav__link">
    SVD Based Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iteration-based-methods-word2vec" title="Iteration Based Methods - Word2vec" class="md-nav__link">
    Iteration Based Methods - Word2vec
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reference" title="Reference" class="md-nav__link">
    Reference
  </a>
  
</li>
      
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Interview experience
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Interview experience
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../面经/" title="我的面经" class="md-nav__link">
      我的面经
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-2" type="checkbox" id="nav-5-2">
    
    <label class="md-nav__link" for="nav-5-2">
      实训笔记
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-2">
        实训笔记
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Protocol Buffers/" title="Protobuf" class="md-nav__link">
      Protobuf
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../FDBus/" title="FDBus" class="md-nav__link">
      FDBus
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../FDBus API/" title="FDBus API" class="md-nav__link">
      FDBus API
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../FDBus内部结构/" title="FDBus内部结构" class="md-nav__link">
      FDBus内部结构
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Cross compiler/" title="Cross compiler" class="md-nav__link">
      Cross compiler
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      For MkDocs
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        For MkDocs
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../MkDocs_demo/" title="Demo" class="md-nav__link">
      Demo
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Material Theme Tutorial/" title="Material Theme Tutorial" class="md-nav__link">
      Material Theme Tutorial
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lecture-01-introduction-and-word-vectors" title="Lecture 01 Introduction and Word Vectors" class="md-nav__link">
    Lecture 01 Introduction and Word Vectors
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#human-language-and-word-meaning" title="Human language and word meaning" class="md-nav__link">
    Human language and word meaning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word2vec-introduction" title="Word2vec introduction" class="md-nav__link">
    Word2vec introduction
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word2vec-objective-function" title="Word2vec objective function" class="md-nav__link">
    Word2vec objective function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word2vec-prediction-function" title="Word2vec prediction function" class="md-nav__link">
    Word2vec prediction function
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes-01-introduction-svd-and-word2vec" title="Notes 01  Introduction, SVD and Word2Vec" class="md-nav__link">
    Notes 01  Introduction, SVD and Word2Vec
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#introduction-to-natural-language-processing" title="Introduction to Natural Language Processing" class="md-nav__link">
    Introduction to Natural Language Processing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#word-vectors" title="Word Vectors" class="md-nav__link">
    Word Vectors
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#svd-based-methods" title="SVD Based Methods" class="md-nav__link">
    SVD Based Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#iteration-based-methods-word2vec" title="Iteration Based Methods - Word2vec" class="md-nav__link">
    Iteration Based Methods - Word2vec
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reference" title="Reference" class="md-nav__link">
    Reference
  </a>
  
</li>
      
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/looperxx/looperxx.github.io/edit/master/docs/CS224n-2019笔记.md" title="编辑此页" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="cs224n-2019">CS224n-2019 笔记<a class="headerlink" href="#cs224n-2019" title="Permanent link">&para;</a></h1>
<ul>
<li>
<p>结合每课时的课件、笔记与推荐读物等整理而成</p>
</li>
<li>
<p>作业部分将单独整理</p>
</li>
</ul>
<h2 id="lecture-01-introduction-and-word-vectors">Lecture 01 Introduction and Word Vectors<a class="headerlink" href="#lecture-01-introduction-and-word-vectors" title="Permanent link">&para;</a></h2>
<p><strong>Lecture Plan</strong></p>
<ul>
<li>The course</li>
<li>Human language and word meaning</li>
<li>Word2vec introduction</li>
<li>Word2vec objective function gradients</li>
<li>Optimization basics</li>
<li>Looking at word vectors</li>
</ul>
<blockquote>
<p>Singular Value Decomposition (SVD) 奇异值分解</p>
</blockquote>
<h3 id="human-language-and-word-meaning">Human language and word meaning<a class="headerlink" href="#human-language-and-word-meaning" title="Permanent link">&para;</a></h3>
<p>人类之所以比类人猿更“聪明”，是因为我们有语言，因此是一个人机网络，其中人类语言作为网络语言。人类语言具有 <strong>信息功能</strong> 和 <strong>社会功能</strong> 。</p>
<p>据估计，人类语言只有大约5000年的短暂历。语言是人类变得强大的主要原因。写作是另一件让人类变得强大的事情。它是使知识能够在空间上传送到世界各地，并在时间上传送的一种工具。</p>
<p>但是，相较于如今的互联网的传播速度而言，人类语言是一种缓慢的语言。然而，只需人类语言形式的几百位信息，就可以构建整个视觉场景。这就是自然语言如此迷人的原因。</p>
<p><strong>How do we represent the meaning of a word?</strong></p>
<p><strong><em>meaning</em></strong></p>
<ul>
<li>用一个词、词组等表示的概念。</li>
<li>一个人想用语言、符号等来表达的想法。</li>
<li>表达在作品、艺术等方面的思想</li>
</ul>
<p>理解意义的最普遍的语言方式(<strong><em>linguistic way</em></strong>) : 语言符号与语言符号的意义的转化
$$
signifier(symbol)\Leftrightarrow signified(idea  or  thing) \
= \textbf{denotational semantics}
$$</p>
<blockquote>
<p>denotational semantics 指称语义</p>
</blockquote>
<p><strong>How do we have usable meaning in a computer?</strong></p>
<p><strong><em>WordNet</em></strong>, 一个包含同义词集和上位词(“is a”关系) <strong><em>synonym sets and hypernyms</em></strong> 的列表的辞典</p>
<div class="superfences-tabs">
<input name="__tabs_1" type="radio" id="__tab_1_0" checked="checked" />
<label for="__tab_1_0">synonym</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">wordnet</span> <span class="k">as</span> <span class="n">wn</span>
<span class="n">poses</span> <span class="o">=</span> <span class="p">{</span> <span class="s1">&#39;n&#39;</span><span class="p">:</span><span class="s1">&#39;noun&#39;</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">:</span><span class="s1">&#39;verb&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">:</span><span class="s1">&#39;adj (s)&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">:</span><span class="s1">&#39;adj&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">:</span><span class="s1">&#39;adv&#39;</span><span class="p">}</span>
<span class="k">for</span> <span class="n">synset</span> <span class="ow">in</span> <span class="n">wn</span><span class="o">.</span><span class="n">synsets</span><span class="p">(</span><span class="s2">&quot;good&quot;</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;{}: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">poses</span><span class="p">[</span><span class="n">synset</span><span class="o">.</span><span class="n">pos</span><span class="p">()],</span>
                    <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">l</span><span class="o">.</span><span class="n">name</span><span class="p">()</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">synset</span><span class="o">.</span><span class="n">lemmas</span><span class="p">()])))</span>
</pre></div>
</td></tr></table></div>
</div>
<p><code>python tab=“hypernyms”
from nltk.corpus import wordnet as wn
panda = wn.synset("panda.n.01")
hyper = lambda s: s.hypernyms()
list(panda.closure(hyper))</code></p>
<p><img alt="同义词" src="../imgs/1560068762906.png" /></p>
<p><img alt="上位词" src="../imgs/1560068729196.png" /></p>
<p><strong>Problems with resources like WordNet</strong></p>
<ul>
<li>作为一个资源很好，但忽略了细微差别<ul>
<li>例如“proficient”被列为“good”的同义词。这只在某些上下文中是正确的。</li>
</ul>
</li>
<li>缺少单词的新含义<ul>
<li>难以持续更新</li>
<li>例如 wicked, badass, nifty, wizard, genius, ninja, bombest</li>
</ul>
</li>
<li>主观的</li>
<li>需要人类劳动来创造和调整</li>
<li>无法计算单词相似度</li>
</ul>
<p><strong>Representing words as discrete symbols</strong></p>
<p>在传统的自然语言处理中，我们把词语看作离散的符号: hotel, conference, motel - a <strong>localist</strong> representation。单词可以通过独热向量(one-hot vectors，只有一个1，其余均为0的稀疏向量) 。向量维度=词汇量(如500,000)。
$$
motel = [0   0   0   0   0   0   0   0   0   0   1   0   0   0   0] \ 
hotel = [0   0   0   0   0   0   0   1   0   0   0   0   0   0   0]
$$
<strong>Problem with words as discrete symbols</strong></p>
<p>所有向量是正交的。对于独热向量，没有关于相似性概念，并且向量维度过大。</p>
<p><strong>Solutions</strong></p>
<ul>
<li>使用类似 <strong><em>WordNet</em></strong> 的工具中的列表，获得相似度，但会因不够完整而失败</li>
<li>学习在向量本身中编码相似性</li>
</ul>
<p><strong>Representing words by their context</strong></p>
<ul>
<li><strong><u>Distributional semantics</u></strong> ：一个单词的意思是由经常出现在它附近的单词给出的<ul>
<li><em>“You shall know a word by the company it keeps”</em> (J. R. Firth 1957: 11)</li>
<li>现代统计NLP最成功的理念之一</li>
<li>有点物以类聚，人以群分的感觉</li>
</ul>
</li>
<li>当一个单词<span><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span>出现在文本中时，它的上下文是出现在其附近的一组单词(在一个固定大小的窗口中)。</li>
<li>使用<span><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span>的许多上下文来构建<span><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span>的表示</li>
</ul>
<p><img alt="示例" src="../imgs/1560069660365.png" /></p>
<h3 id="word2vec-introduction">Word2vec introduction<a class="headerlink" href="#word2vec-introduction" title="Permanent link">&para;</a></h3>
<p>我们为每个单词构建一个 <strong>密集</strong> 的向量，使其与出现在相似上下文中的单词向量相似</p>
<p>词向量 <strong><em>word vectors</em></strong> 有时被称为词嵌入 <strong><em>word embeddings</em></strong>  或词表示 <strong><em>word representations</em></strong>  </p>
<p>它们是分布式表示 <strong><em>distributed representation</em></strong>
$$
\mathrm{banking} = \left[\begin{matrix}0.286 \0.792 \-0.177 \-0.107 \0.109 \-0.542 \0.349 \0.271 \end{matrix}\right]
$$
<strong><em>Word2vec</em></strong> (Mikolov et al. 2013)是一个学习单词向量的 <strong>框架</strong> </p>
<p>Idea：</p>
<ul>
<li>我们有大量的文本 (corpus means 'body' in Latin. 复数为corpora)</li>
<li>固定词汇表中的每个单词都由一个向量表示</li>
<li>文本中的每个位置 <span><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span>，其中有一个中心词 <span><span class="MathJax_Preview">c</span><script type="math/tex">c</script></span> 和上下文(“外部”)单词 <span><span class="MathJax_Preview">o</span><script type="math/tex">o</script></span> </li>
<li>使用 <span><span class="MathJax_Preview">c</span><script type="math/tex">c</script></span> 和 <span><span class="MathJax_Preview">o</span><script type="math/tex">o</script></span> 的 <strong>词向量的相似性</strong> 来计算给定 <span><span class="MathJax_Preview">c</span><script type="math/tex">c</script></span> 的 <span><span class="MathJax_Preview">o</span><script type="math/tex">o</script></span> 的 <strong>概率</strong> (反之亦然)</li>
<li><strong>不断调整词向量</strong> 来最大化这个概率</li>
</ul>
<p>下图为窗口大小 <span><span class="MathJax_Preview">j=2</span><script type="math/tex">j=2</script></span> 时的 <span><span class="MathJax_Preview">P\left(w_{t+j} | w_{t}\right)</span><script type="math/tex">P\left(w_{t+j} | w_{t}\right)</script></span> 计算过程，center word分别为 <span><span class="MathJax_Preview">into</span><script type="math/tex">into</script></span> 和 <span><span class="MathJax_Preview">banking</span><script type="math/tex">banking</script></span></p>
<p><img alt="1560070410531" src="../imgs/1560070410531.png" /></p>
<p><img alt="1560070494437" src="../imgs/1560070494437.png" /></p>
<h3 id="word2vec-objective-function">Word2vec objective function<a class="headerlink" href="#word2vec-objective-function" title="Permanent link">&para;</a></h3>
<p>对于每个位置<span><span class="MathJax_Preview">t=1, \ldots, T</span><script type="math/tex">t=1, \ldots, T</script></span> ，在大小为<span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span>的固定窗口内预测上下文单词，给定中心词 <span><span class="MathJax_Preview">w_j</span><script type="math/tex">w_j</script></span></p>
<div>
<div class="MathJax_Preview">
Likelihoood = L(\theta) = \prod^{T}_{t=1} \prod_{-m \leq j \leq m \atop j \neq 0} P(w_{t+j} | w_{t} ; \theta)
</div>
<script type="math/tex; mode=display">
Likelihoood = L(\theta) = \prod^{T}_{t=1} \prod_{-m \leq j \leq m \atop j \neq 0} P(w_{t+j} | w_{t} ; \theta)
</script>
</div>
<ul>
<li>其中，<span><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span> 为所有需要优化的变量</li>
</ul>
<p>目标函数<span><span class="MathJax_Preview">J(\theta)</span><script type="math/tex">J(\theta)</script></span> (有时被称为代价函数或损失函数) 是(平均)负对数似然
$$
J(\theta)=-\frac{1}{T} \log L(\theta)=-\frac{1}{T} \sum_{t=1}^{T} \sum_{-m \leq j \leq m \atop j \neq 0} \log P\left(w_{t+j} | w_{t} ; \theta\right)
$$
其中log形式是方便将联乘转化为求和，负号是希望将极大化似然率转化为极小化损失函数的等价问题。</p>
<ul>
<li><strong>最小化目标函数 <span><span class="MathJax_Preview">\Leftrightarrow</span><script type="math/tex">\Leftrightarrow</script></span>  最大化预测精度</strong></li>
<li><u>问题</u>：如何计算 $  P(w_{t+j} | w_{t} ; \theta)$ ？</li>
<li><u>回答</u>：对于每个单词都是用两个向量<ul>
<li><span><span class="MathJax_Preview">v_w</span><script type="math/tex">v_w</script></span> 当 <span><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span> 是中心词时</li>
<li><span><span class="MathJax_Preview">u_w</span><script type="math/tex">u_w</script></span> 当 <span><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span> 是上下文词时</li>
</ul>
</li>
<li>于是对于一个中心词 <span><span class="MathJax_Preview">c</span><script type="math/tex">c</script></span> 和一个上下文词  <span><span class="MathJax_Preview">o</span><script type="math/tex">o</script></span> </li>
</ul>
<div>
<div class="MathJax_Preview">
P(o | c)=\frac{\exp \left(u_{o}^{T} v_{c}\right)}{\sum_{w \in V} \exp \left(u_{w}^{T} v_{c}\right)}
</div>
<script type="math/tex; mode=display">
P(o | c)=\frac{\exp \left(u_{o}^{T} v_{c}\right)}{\sum_{w \in V} \exp \left(u_{w}^{T} v_{c}\right)}
</script>
</div>
<h3 id="word2vec-prediction-function">Word2vec prediction function<a class="headerlink" href="#word2vec-prediction-function" title="Permanent link">&para;</a></h3>
<div>
<div class="MathJax_Preview">
P(o | c)=\frac{\exp \left(u_{o}^{T} v_{c}\right)}{\sum_{w \in V} \exp \left(u_{w}^{T} v_{c}\right)}
</div>
<script type="math/tex; mode=display">
P(o | c)=\frac{\exp \left(u_{o}^{T} v_{c}\right)}{\sum_{w \in V} \exp \left(u_{w}^{T} v_{c}\right)}
</script>
</div>
<ul>
<li>取幂使任何数都为正</li>
<li>点积比较o和c的相似性 <span><span class="MathJax_Preview">u^{T} v=u . v=\sum_{i=1}^{n} u_{i} v_{i}</span><script type="math/tex">u^{T} v=u . v=\sum_{i=1}^{n} u_{i} v_{i}</script></span> ，点积越大则概率越大</li>
<li>分母：对整个词汇表进行标准化，从而给出概率分布</li>
</ul>
<p><strong>softmax function</strong> <span><span class="MathJax_Preview">\mathbb{R}^{n} \rightarrow \mathbb{R}^{n}</span><script type="math/tex">\mathbb{R}^{n} \rightarrow \mathbb{R}^{n}</script></span>
$$
\operatorname{softmax}\left(x_{i}\right)=\frac{\exp \left(x_{i}\right)}{\sum_{j=1}^{n} \exp \left(x_{j}\right)}=p_{i}
$$
将任意值 <span><span class="MathJax_Preview">x_i</span><script type="math/tex">x_i</script></span> 映射到概率分布 <span><span class="MathJax_Preview">p_i</span><script type="math/tex">p_i</script></span></p>
<ul>
<li><strong>max</strong> ：因为放大了最大的概率</li>
<li><strong>soft</strong> ：因为仍然为较小的 <span><span class="MathJax_Preview">x_i</span><script type="math/tex">x_i</script></span> 赋予了一定概率</li>
<li>深度学习中常用</li>
</ul>
<p>梯度下降，随机梯度下降以及链式求导法则的知识在此不再赘述，你可以在 <strong>Reference</strong> 部分找到你需要的资料<img alt="😄" class="emojione" src="https://cdn.jsdelivr.net/emojione/assets/svg/1f604.svg" title=":smile:" /></p>
<h2 id="notes-01-introduction-svd-and-word2vec">Notes 01  Introduction, SVD and Word2Vec<a class="headerlink" href="#notes-01-introduction-svd-and-word2vec" title="Permanent link">&para;</a></h2>
<p><strong>Keyphrases: Natural Language Processing. Word Vectors. Singular Value Decomposition. Skip-gram. Continuous Bag of Words</strong>
<strong>(CBOW). Negative Sampling. Hierarchical Softmax. Word2Vec.</strong></p>
<blockquote>
<p>这组笔记首先介绍了自然语言处理(NLP)的概念及其面临的问题。然后我们继续讨论将单词表示为数字向量的概念。最后，讨论了常用的词向量设计方法。</p>
</blockquote>
<h3 id="introduction-to-natural-language-processing">Introduction to Natural Language Processing<a class="headerlink" href="#introduction-to-natural-language-processing" title="Permanent link">&para;</a></h3>
<p><strong>What is so special about NLP?</strong></p>
<p>Natural language is a discrete/symbolic/categorical system </p>
<blockquote>
<p>离散的/符号的/分类的</p>
</blockquote>
<p>人类的语言有什么特别之处？人类语言是一个专门用来表达意义的系统，而不是由任何形式的物理表现产生的。在这方面上，它与视觉或任何其他机器学习任务都有很大的不同。</p>
<p>大多数单词只是一个语言学以外的的符号：单词是一个映射到所指(signified 想法或事物)的能指(signifier)。</p>
<p>例如，“rocket”一词指的是火箭的概念，因此可以引申为火箭的实例。当我们使用单词和字母来表达符号时，也会有一些例外，例如“whoompaa”的使用。最重要的是，这些语言的符号可以被 编码成几种形式：声音、手势、文字等等，然后通过连续的信号传输给大脑，大脑本身似乎也能以一种连续的方式对这些信号进行解码。人们在语言哲学和语言学方面做了大量的工作来概念化人类语言，并将词语与其参照、意义等区分开来。</p>
<p><strong>Examples of tasks</strong></p>
<p>自然语言处理有不同层次的任务，从语言处理到语义解释再到语篇处理。自然语言处理的目标是通过设计算法使得计算机能够“理解”语言，从而能够执行某些特定的任务。不同的任务的难度是不一样的</p>
<p><strong>Easy</strong></p>
<ul>
<li>拼写检查  Spell Checking</li>
<li>关键词检索 Keyword Search</li>
<li>同义词查找  Finding Synonyms</li>
</ul>
<p><strong>Medium</strong></p>
<ul>
<li>解析来自网站、文档等的信息</li>
</ul>
<p><strong>Hard</strong></p>
<ul>
<li>机器翻译  Machine Translation</li>
<li>语义分析  Semantic Analysis</li>
<li>指代消解  Coreference</li>
<li>问答系统  Question Answering</li>
</ul>
<p><strong>How to represent words?</strong></p>
<p>在所有的NLP任务中，第一个也是可以说是最重要的共同点是我们如何将单词表示为任何模型的输入。在这里我们不会讨论早期的自然语言处理工作是将单词视为原子符号 atomic symbols。为了让大多数的自然语言处理任务能有更好的表现，我们首先需要了解单词之间的相似和不同。有了词向量，我们可以很容易地将其编码到向量本身中。</p>
<h3 id="word-vectors">Word Vectors<a class="headerlink" href="#word-vectors" title="Permanent link">&para;</a></h3>
<p>使用词向量编码单词，N维空间足够我们编码语言的所有语义，每一维度都会编码一些我们使用语言传递的信息。简单的one-hot向量无法给出单词间的相似性，我们需要将维度  <span><span class="MathJax_Preview">|V|</span><script type="math/tex">|V|</script></span>  减少至一个低纬度的子空间，来获得稠密的词向量，获得词之间的关系。</p>
<h3 id="svd-based-methods">SVD Based Methods<a class="headerlink" href="#svd-based-methods" title="Permanent link">&para;</a></h3>
<p>这是一类找到词嵌入的方法（即词向量），我们首先遍历一个很大的数据集和统计词的共现计数矩阵 X，然后对矩阵 X 进行 SVD 分解得到 <span><span class="MathJax_Preview">USV^{T}</span><script type="math/tex">USV^{T}</script></span> 。然后我们使用 U 的行来作为字典中所有词的词向量。我们来讨论一下矩阵 X 的几种选择。</p>
<p><strong>Word-Document Matrix</strong></p>
<p>我们最初的尝试，我们猜想相关连的单词在同一个文档中会经常出现。例如，“banks”，“bonds”，“stocks”，“moneys”等等，出现在一起的概率会比较高。但是“banks”，“octopus”，“banana”，“hockey”不大可能会连续地出现。我们根据这个情况来建立一个 <strong><em>Word-Document</em></strong> 矩阵，<span><span class="MathJax_Preview">X</span><script type="math/tex">X</script></span> 是按照以下方式构建：遍历数亿的文档和当词 <span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> 出现在文档 <span><span class="MathJax_Preview">j</span><script type="math/tex">j</script></span>，我们对 <span><span class="MathJax_Preview">X_{ij}</span><script type="math/tex">X_{ij}</script></span> 加一。这显然是一个很大的矩阵 <span><span class="MathJax_Preview">\mathbb{R}^{|V|\times M}</span><script type="math/tex">\mathbb{R}^{|V|\times M}</script></span>，它的规模是和文档数量 <span><span class="MathJax_Preview">M</span><script type="math/tex">M</script></span> 成正比关系。因此我们可以尝试更好的方法。</p>
<p><strong>Window based Co-occurrence Matrix</strong></p>
<p>同样的逻辑也适用于这里，但是矩阵 <span><span class="MathJax_Preview">X</span><script type="math/tex">X</script></span> 存储单词的共现，从而成为一个关联矩阵。在此方法中，我们计算每个单词在特定大小的窗口中出现的次数。我们按照这个方法对语料库中的所有单词进行统计。</p>
<ul>
<li>生成维度为 <span><span class="MathJax_Preview">|V| \times|V|</span><script type="math/tex">|V| \times|V|</script></span> 的共现矩阵<span><span class="MathJax_Preview">X</span><script type="math/tex">X</script></span></li>
<li>在 <span><span class="MathJax_Preview">X</span><script type="math/tex">X</script></span> 上应用 <strong>SVD</strong> 从而得到 <span><span class="MathJax_Preview">X = {USV}^T</span><script type="math/tex">X = {USV}^T</script></span> </li>
<li>选择 <span><span class="MathJax_Preview">U</span><script type="math/tex">U</script></span> 前 <span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span> 行 得到 <span><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span> 维的词向量</li>
<li><span><span class="MathJax_Preview">\frac{\sum_{i=1}^{k} \sigma_{i}}{\sum_{i=1}^{|V|} \sigma_{i}}</span><script type="math/tex">\frac{\sum_{i=1}^{k} \sigma_{i}}{\sum_{i=1}^{|V|} \sigma_{i}}</script></span> 表示第一个k维捕获的方差量</li>
</ul>
<p><strong>Applying SVD to the cooccurrence matrix</strong></p>
<p>我们对矩阵 <span><span class="MathJax_Preview">X</span><script type="math/tex">X</script></span> 使用 SVD，观察奇异值（矩阵 S 上对角线上元素），根据期望的捕获方差百分比截断，留下前 k 个元素：</p>
<p>然后取子矩阵 <span><span class="MathJax_Preview">U_{1:|V|, 1:k}</span><script type="math/tex">U_{1:|V|, 1:k}</script></span> 作为词嵌入矩阵。这就给出了词汇表中每个词的 k 维表示</p>
<p>对矩阵 <span><span class="MathJax_Preview">X</span><script type="math/tex">X</script></span> 使用SVD</p>
<p><img alt="1560082218689" src="../imgs/1560082218689.png" /></p>
<p>通过选择前 k 个奇异向量来降低维度</p>
<p><img alt="1560082288451" src="../imgs/1560082288451.png" /></p>
<p>这两种方法都给我们提供了足够的词向量来编码语义和句法(part of speech)信息，但伴随许多其他问题</p>
<ul>
<li>矩阵的维度会经常发生改变（经常增加新的单词和语料库的大小会改变）。</li>
<li>矩阵会非常的稀疏，因为很多词不会共现。</li>
<li>矩阵维度一般会非常高 <span><span class="MathJax_Preview">\approx 10^{6}\times 10^{6}</span><script type="math/tex">\approx 10^{6}\times 10^{6}</script></span></li>
<li>基于 SVD 的方法的计算复杂度很高 ( <span><span class="MathJax_Preview">m×n</span><script type="math/tex">m×n</script></span> 矩阵的计算成本是 <span><span class="MathJax_Preview">O({mn}^2)</span><script type="math/tex">O({mn}^2)</script></span> )，并且很难合并新单词或文档</li>
<li>需要在 X 上加入一些技巧处理来解决词频的极剧的不平衡</li>
<li>需要在 X 上加入一些技巧处理来解决词频的极剧的不平衡</li>
</ul>
<p>然而，基于计数的方法可以有效地利用统计量</p>
<p>对上述讨论中存在的问题存在以下的解决方法：</p>
<ul>
<li>忽略功能词，例如 “the”，“he”，“has” 等等。</li>
<li>使用 ramp window，即根据文档中单词之间的距离对共现计数进行加权</li>
<li>使用皮尔逊相关系数并将负计数设置为0，而不是只使用原始计数</li>
</ul>
<p>正如我们在下一节中看到的，基于迭代的方法以一种优雅得多的方式解决了大部分上述问题。</p>
<h3 id="iteration-based-methods-word2vec">Iteration Based Methods - Word2vec<a class="headerlink" href="#iteration-based-methods-word2vec" title="Permanent link">&para;</a></h3>
<p>这里我们尝试一个新的方法。我们可以尝试创建一个模型，该模型能够一次学习一个迭代，并最终能够对给定上下文的单词的概率进行编码，而不是计算和存储一些大型数据集(可能是数十亿个句子)的全局信息。</p>
<p>这个想法是设计一个模型，该模型的参数就是词向量。然后根据一个目标函数训练模型，在每次模型的迭代计算误差，并遵循一些更新规则，该规则具有惩罚造成错误的模型参数的作用，从而可以学习到词向量。这个方法可以追溯到 1986年，我们称这个方法为“反向传播”，模型和任务越简单，训练它的速度就越快。</p>
<ul>
<li>基于迭代的方法一次捕获一个单词的共现情况，而不是像SVD方法那样直接捕获所有的共现计数。</li>
</ul>
<p>已经很多人按照这个思路测试了不同的方法。[Collobert et al., 2011] 设计的模型首先将每个单词转换为向量。对每个特定的任务（命名实体识别、词性标注等等），他们不仅训练模型的参数，同时也训练单词向量，计算出了非常好的词向量的同时取得了很好的性能。</p>
<p>在这里，我们介绍一个非常有效的概率模型：Word2vec。Word2vec 是一个软件包实际上包含：</p>
<ul>
<li><strong>两个算法</strong>：continuous bag-of-words（CBOW）和 skip-gram。CBOW 是根据中心词周围的上下文单词来预测该词的词向量。skip-gram 则相反，是根据中心词预测周围上下文的词的概率分布。</li>
<li>**两个训练方法：**negative sampling 和 hierarchical softmax。Negative sampling 通过抽取负样本来定义目标，hierarchical softmax 通过使用一个有效的树结构来计算所有词的概率来定义目标。</li>
</ul>
<p><strong>Language Models (Unigrams, Bigrams, etc.)</strong></p>
<p>首先，我们需要创建一个模型来为一系列的单词分配概率。我们从一个例子开始：</p>
<p>“The cat jumped over the puddle”</p>
<p>一个好的语言模型会给这个句子很高的概率，因为在句法和语义上这是一个完全有效的句子。相似地，句子“stock boil fish is toy”会得到一个很低的概率，因为这是一个无意义的句子。在数学上，我们可以称为对给定 n 个词的序列的概率是：
$$
P(w_{1}, w_{2}, \ldots, w_{n})
$$
我们可以采用一元语言模型方法(<strong>Unigram model</strong>)，假设单词的出现是完全独立的，从而分解概率
$$
P\left(w_{1}, w_{2}, \cdots, w_{n}\right)=\prod_{i=1}^{n} P\left(w_{i}\right)
$$
但是我们知道这是不大合理的，因为下一个单词是高度依赖于前面的单词序列的。如果使用上述的语言模型，可能会让一个无意义的句子具有很高的概率。所以我们让序列的概率取决于序列中的单词和其旁边的单词的成对概率。我们称之为 bigram 模型：
$$
P\left(w_{1}, w_{2}, \cdots, w_{n}\right)=\prod_{i=2}^{n} P\left(w_{i} | w_{i-1}\right)
$$
但是，这个方法还是有点简单，因为我们只关心一对邻近的单词，而不是针对整个句子来考虑。但是我们将看到，这个方法会有显著的提升。考虑在词-词共现矩阵中，共现窗口为 1，我们基本上能得到这样的成对的概率。但是，这又需要计算和存储大量数据集的全局信息。</p>
<p>既然我们已经理解了如何考虑具有概率的单词序列，那么让我们观察一些能够学习这些概率的示例模型。</p>
<p><strong>Continuous Bag of Words Model (CBOW)</strong></p>
<h2 id="reference">Reference<a class="headerlink" href="#reference" title="Permanent link">&para;</a></h2>
<p>以下是学习本课程时的可用参考书籍：</p>
<p><a href="https://nndl.github.io/">《神经网络与深度学习》</a></p>
<p>以下是整理笔记的过程中参考的博客：</p>
<p><a href="https://zhuanlan.zhihu.com/p/59011576">斯坦福CS224N深度学习自然语言处理2019冬学习笔记目录</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/61625439">斯坦福NLP课程 CS224N Winter 2019 学习笔记</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/31977759">斯坦福大学 CS224n自然语言处理与深度学习笔记汇总</a> (这是针对note部分的翻译)</p>
                
                  
                
              
              
                


  <h2 id="__comments">评论</h2>
  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = "https://looperxx.github.io/CS224n-2019笔记/";
      this.page.identifier =
        "/CS224n-2019笔记/";
    };
    (function() {
      var d = document, s = d.createElement("script");
      s.src = "//https-looperxx-github-io-my-wiki.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>

              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../CS224n-2019简介/" title="CS224n-2019简介" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  后退
                </span>
                CS224n-2019简介
              </span>
            </div>
          </a>
        
        
          <a href="../面经/" title="我的面经" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  前进
                </span>
                我的面经
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 - 2020 Looper Xiao Xu
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../assets/fonts/font-awesome.css">
    
      <a href="https://github.com/LooperXX" class="md-footer-social__link fa fa-github"></a>
    
      <a href="https://www.linkedin.com/in/%E5%95%B8-%E5%BE%90-012456163/" class="md-footer-social__link fa fa-linkedin"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.39abc4af.js"></script>
      
        
        
          
          <script src="../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
                <script src="../assets/javascripts/lunr/tinyseg.js"></script>
              
              
                <script src="../assets/javascripts/lunr/lunr.ja.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>