# Neural Reading Comprehension and beyond 阅读笔记

##  Chapter 1	Introduction

- 怎样叫做理解人类语言？
  - 词性标注 `part-of-speech tagging` 
    - 专有名词 常用名词 动词 形容词 介词
  - 命名实体识别 `named entity recognition` 
    - 人名 地名
  - 句法分析 `syntactic parsing`
    - 理解每一个句子
      - 单词之间的关系
      - 语法结构
  - 共指消解/指代消解 `coreference resolution`
    - 句子之间的相互作用
      - She 指代上文的 A
      - The girls 指代上文的 ABCD

- 如何全面地测试评估这些方面？
  - 阅读理解——基于一段文本回答阅读理解问题
 ![1554646276629](imgs/1554646276629.png)
  - 计算机系统必须理解文本的许多不同方面才能正确回答这些问题
  - 本论文的核心主题之一：由于可以设计问题来检测我们关心的某些方面，阅读理解可能是评估语言理解的最合适的任务

- 最近阅读理解的成功是为什么？

  - `(passage, question, answer)`的三元组的形式创建大规模的监督数据集
  - 神经阅读理解模型的发展

- 在本论文中，我们将涵盖现代神经阅读理解的本质

  - 问题的形成，这些系统的构建模块和关键成分，以及对当前神经阅读理解系统可以在哪些方面取得优势以及它们仍然落后的地方的理解

- 论文的第二个中心主题

  - 我们深信，如果我们能够建立表现优秀的阅读理解系统，它们将成为问答和对话系统等应用的关键技术

- 阅读理解可以促进更加智能的搜索引擎

![1554646924922](imgs/1554646924922.png)

  - google不仅返回搜索文档列表，还尝试阅读这些Web文档，最后突出显示最合理的答案并将其显示在搜索结果的顶部

- 本文还对如何从最近神经阅读理解的成功构建实际应用做了探索

  - 开放领域问答 `Open-domain question answering`
    - 结合了信息检索和阅读理解的挑战，旨在回答来自Web或大型百科全书（例如维基百科）的一般问题
  - 会话问答 `Conversational question answering`
    - 结合了对话和阅读理解的挑战，并解决了在文本段落中多回合问题回答的问题，例如用户如何与会话代理人交流

![1554647157744](imgs/1554647157744.png)

- 本文构成
  - 基础
    - 侧重于阅读理解的任务，重点是仔细阅读一个短段，以便计算机系统能够回答理解问题
    - 第二章
      - 我们首先概述了阅读理解领域的历史和最新发展。接下来，我们正式定义问题的表述及其主要类别。
      - 然后，我们简要讨论阅读理解和一般问题回答的差异。
      - 最后，我们认为最近神经阅读理解的成功是由大规模数据集和神经模型驱动的。
    - 第三章
      - 我们介绍了神经阅读理解模型的家族。我们首先描述非神经的，基于特征的分类器，并讨论它们与端到端神经方法的区别。
      - 然后我们介绍一种我们提出的名为`THE STANFORD ATTENTIVE READER`的神经方法，并描述其基本构建块和扩展。我们在两个有代表性的阅读理解数据集上呈现实验结果：`CNN/DAILY MAIL`和`SQUAD`，更重要的是，我们对神经模型进行了深入分析，以更好地理解这些模型实际学到了什么。
      - 最后，我们总结了神经阅读理解模型在不同方面的最新进展。
      - 本章基于我们的工作。(Chen et al.,2016), (Chen et al.,2017)
    - 第四章
      - 我们将讨论该领域的未来工作和未解决的问题。我们首先检查现有模型的错误情况，尽管它们在当前的基准测试中具有很高的准确性。
      - 然后，我们将讨论数据集和模型的未来方向。
      - 最后，我们回顾了该领域的几个重要研究问题，这些问题仍然是一个悬而未决的问题，未来还有待回答。
  - 应用
    - 将阅读理解视为实际应用的重要组成部分，例如问答系统和会话代理（对话系统）
    - 第五章
      - 我们将开放领域问答系统的问题作为阅读理解的应用来解决。我们讨论如何将高性能神经阅读理解系统与有效的信息检索技术相结合，构建新一代开放领域问答系统。
      - 我们描述了一个我们建立的名为`DRQA`的系统：它的关键组件以及我们如何为它创建训练集，然后我们对多个QA基准进行全面评估。
      - 我们最后讨论了它目前的局限性和未来的工作。本章基于我们的工作(Chen et al., 2017)
    - 第六章
      - 我们研究了会话代理的问题，其中机器必须理解文本段落并回答出现在对话中的一系列问题。
      - 我们首先简要回顾一下有关对话的文献，并认为对话问题回答是建立信息寻求对话代理人的关键。
      - 我们介绍了`COQA`：一个用于构建会话问答系统的新数据集，包括127k问题和答案，从8k关于文本段落的对话中获得。
      - 我们深入分析数据集，并在会话和神经阅读理解模型之上构建几个竞争模型，并展示实验结果。
        我们终于讨论了这个领域的未来工作。本章基于我们的工作(Reddy et al., 2019)。
    - 第七章
      - 总结
- 本文贡献
  - 第一批研究神经阅读理解的人。特别是，我们提出了`STANFORD ATTENTIVE READER`模型，该模型在各种现代阅读理解任务中表现出优越的性能
  - 我们努力更好地理解神经阅读理解模型实际学到了什么，以及解决当前任务需要多大的语言理解深度。我们得出结论，与传统的基于特征的分类器相比，神经模型更好地学习词汇匹配和释义，而现有系统的推理能力仍然相当有限。
  - 我们开创了将神经阅读理解作为开放域问答的核心组成部分的研究方向，并研究了如何推广该案例的模型。特别是，我们在`DRQA`系统中实现了这一想法，`DRQA`系统是基于英语维基百科的一个大型，仿真问答系统。
  - 最后，我们着手解决会话问题回答问题，其中计算机系统需要在对话环境中回答理解问题，因此每个问题都需要通过其对话历史来理解。为解决这个问题，我们提出了`COQA`挑战，并建立了适应这一问题的神经阅读理解模型。我们相信这是构建对话QA代理的第一步，也是重要的一步。

##  Neural Reading Comprehension:Foundations

##  Chapter 2	An Overview of Reading Comprehension

- waiting